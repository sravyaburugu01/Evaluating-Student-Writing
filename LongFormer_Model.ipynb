{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Student Writing\n",
    "We aim to identify elements in student writing i.e. we segment text and classify argumentative and rhetorical elements i.e. predict human annotations in essays written by 6th-12th\n",
    "grade students.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The demo and visualisation on the test data is at the end of the file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:42:39.137763Z",
     "iopub.status.busy": "2022-05-05T20:42:39.137439Z",
     "iopub.status.idle": "2022-05-05T20:43:40.444611Z",
     "shell.execute_reply": "2022-05-05T20:43:40.443308Z",
     "shell.execute_reply.started": "2022-05-05T20:42:39.137674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "     |████████████████████████████████| 43 kB 178 kB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (3.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.7.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=5c2e0aa8849cf0347e9ddf29b82f81ec1962982dbec2d2ec7c8ee4e52d34e745\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.12.7)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.5.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.19.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.24)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.8.0)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from wandb) (5.1.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.8)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb) (4.8.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install libraries to get evaluation metrics for training data\n",
    "!pip install seqeval\n",
    "!pip install seqeval -qq \n",
    "!pip install wandb\n",
    "!pip install --upgrade wandb -qq \n",
    "import wandb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# visualization with displacy\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from pylab import cm, matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Model to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:43:40.447641Z",
     "iopub.status.busy": "2022-05-05T20:43:40.447283Z",
     "iopub.status.idle": "2022-05-05T20:43:42.427496Z",
     "shell.execute_reply": "2022-05-05T20:43:42.426464Z",
     "shell.execute_reply.started": "2022-05-05T20:43:40.447593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the model to run: \n",
      " 1. LongFormer \n",
      " 2. BigBird\n",
      "Kindly enter 1 or 2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model choosen is Longformer\n"
     ]
    }
   ],
   "source": [
    "print(\"Choose the model to run: \\n 1. LongFormer \\n 2. BigBird\")\n",
    "print(\"Kindly enter 1 or 2\")\n",
    "while True:\n",
    "    input_model = input()\n",
    "    if len(input_model)>1:\n",
    "        print(\"Invalid Input, Kindly enter 1 or 2\")\n",
    "    else:\n",
    "        if input_model == '1':\n",
    "            model_checkpoint = \"allenai/longformer-base-4096\"\n",
    "            print(\"The model choosen is Longformer\")\n",
    "            break\n",
    "        elif input_model == '2':\n",
    "            model_checkpoint = \"google/bigbird-roberta-base\"\n",
    "            print(\"The model choosen is BigBird\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid Input, Kindly enter 1 or 2\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-05T20:43:42.429623Z",
     "iopub.status.busy": "2022-05-05T20:43:42.428984Z",
     "iopub.status.idle": "2022-05-05T20:43:42.437316Z",
     "shell.execute_reply": "2022-05-05T20:43:42.436000Z",
     "shell.execute_reply.started": "2022-05-05T20:43:42.429540Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configurations\n",
    "\n",
    "SAMPLE =  False # Used for debugging\n",
    "\n",
    "EXP_NUM = 4\n",
    "task = \"ner\"\n",
    "max_length = 1024\n",
    "stride = 128\n",
    "min_tokens = 6\n",
    "model_path = f'{model_checkpoint.split(\"/\")[-1]}-{EXP_NUM}'\n",
    "max_length = 1024\n",
    "batch_size = 4 \n",
    "\n",
    "# TRAINING HYPERPARAMS\n",
    "BS = 4\n",
    "GRAD_ACC = 8\n",
    "LR = 5e-5\n",
    "WD = 0.01\n",
    "WARMUP = 0.1\n",
    "N_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:43:42.441840Z",
     "iopub.status.busy": "2022-05-05T20:43:42.441014Z",
     "iopub.status.idle": "2022-05-05T20:43:44.141921Z",
     "shell.execute_reply": "2022-05-05T20:43:44.141016Z",
     "shell.execute_reply.started": "2022-05-05T20:43:42.441737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importing the train data\n",
    "train = pd.read_csv('../input/feedback-prize-2021/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:43:44.144247Z",
     "iopub.status.busy": "2022-05-05T20:43:44.143667Z",
     "iopub.status.idle": "2022-05-05T20:43:44.168296Z",
     "shell.execute_reply": "2022-05-05T20:43:44.167130Z",
     "shell.execute_reply.started": "2022-05-05T20:43:44.144200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lead',\n",
       " 'Position',\n",
       " 'Evidence',\n",
       " 'Claim',\n",
       " 'Concluding Statement',\n",
       " 'Counterclaim',\n",
       " 'Rebuttal']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the unique classes in the dataset\n",
    "classes = train.discourse_type.unique().tolist()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:43:44.170789Z",
     "iopub.status.busy": "2022-05-05T20:43:44.170112Z",
     "iopub.status.idle": "2022-05-05T20:43:44.185915Z",
     "shell.execute_reply": "2022-05-05T20:43:44.184553Z",
     "shell.execute_reply.started": "2022-05-05T20:43:44.170743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Lead\n",
      "1 Position\n",
      "2 Evidence\n",
      "3 Claim\n",
      "4 Concluding Statement\n",
      "5 Counterclaim\n",
      "6 Rebuttal\n"
     ]
    }
   ],
   "source": [
    "# Setting label incides\n",
    "from collections import defaultdict\n",
    "tags = defaultdict()\n",
    "\n",
    "for i, c in enumerate(classes):\n",
    "    print(i,c)\n",
    "    tags[f'B-{c}'] = i\n",
    "    tags[f'I-{c}'] = i + len(classes)\n",
    "tags[f'O'] = len(classes) * 2\n",
    "tags[f'Special'] = -100\n",
    "    \n",
    "l2i = dict(tags)\n",
    "\n",
    "i2l = defaultdict()\n",
    "for k, v in l2i.items(): \n",
    "    i2l[v] = k\n",
    "i2l[-100] = 'Special'\n",
    "\n",
    "i2l = dict(i2l)\n",
    "\n",
    "N_LABELS = len(i2l) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:43:44.188401Z",
     "iopub.status.busy": "2022-05-05T20:43:44.188174Z",
     "iopub.status.idle": "2022-05-05T20:43:44.197780Z",
     "shell.execute_reply": "2022-05-05T20:43:44.196533Z",
     "shell.execute_reply.started": "2022-05-05T20:43:44.188373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'B-Lead': 0,\n",
       "             'I-Lead': 7,\n",
       "             'B-Position': 1,\n",
       "             'I-Position': 8,\n",
       "             'B-Evidence': 2,\n",
       "             'I-Evidence': 9,\n",
       "             'B-Claim': 3,\n",
       "             'I-Claim': 10,\n",
       "             'B-Concluding Statement': 4,\n",
       "             'I-Concluding Statement': 11,\n",
       "             'B-Counterclaim': 5,\n",
       "             'I-Counterclaim': 12,\n",
       "             'B-Rebuttal': 6,\n",
       "             'I-Rebuttal': 13,\n",
       "             'O': 14,\n",
       "             'Special': -100})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the tags assigned to the classes\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:43:44.200306Z",
     "iopub.status.busy": "2022-05-05T20:43:44.199487Z",
     "iopub.status.idle": "2022-05-05T20:43:44.211162Z",
     "shell.execute_reply": "2022-05-05T20:43:44.210101Z",
     "shell.execute_reply.started": "2022-05-05T20:43:44.200258Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading raw text from the essay files\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('../input/feedback-prize-2021/train')\n",
    "\n",
    "def get_raw_text(ids):\n",
    "    with open(path/f'{ids}.txt', 'r') as file: data = file.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:43:44.213475Z",
     "iopub.status.busy": "2022-05-05T20:43:44.213091Z",
     "iopub.status.idle": "2022-05-05T20:44:45.341109Z",
     "shell.execute_reply": "2022-05-05T20:44:45.339981Z",
     "shell.execute_reply.started": "2022-05-05T20:43:44.213416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grouping annotations based on discourse_type, discourse_start, discourse_end and \n",
    "# predictionstring to form single tuple for each essay\n",
    "\n",
    "df1 = train.groupby('id')['discourse_type'].apply(list).reset_index(name='classlist')\n",
    "df2 = train.groupby('id')['discourse_start'].apply(list).reset_index(name='starts')\n",
    "df3 = train.groupby('id')['discourse_end'].apply(list).reset_index(name='ends')\n",
    "df4 = train.groupby('id')['predictionstring'].apply(list).reset_index(name='predictionstrings')\n",
    "\n",
    "#Merging the dataframes\n",
    "df = pd.merge(df1, df2, how='inner', on='id')\n",
    "df = pd.merge(df, df3, how='inner', on='id')\n",
    "df = pd.merge(df, df4, how='inner', on='id')\n",
    "\n",
    "#Adding raw essay text to the merged data\n",
    "df['text'] = df['id'].apply(get_raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:44:45.346267Z",
     "iopub.status.busy": "2022-05-05T20:44:45.345992Z",
     "iopub.status.idle": "2022-05-05T20:44:45.369341Z",
     "shell.execute_reply": "2022-05-05T20:44:45.368174Z",
     "shell.execute_reply.started": "2022-05-05T20:44:45.346227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>classlist</th>\n",
       "      <th>starts</th>\n",
       "      <th>ends</th>\n",
       "      <th>predictionstrings</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>[Position, Evidence, Evidence, Claim, Counterc...</td>\n",
       "      <td>[0.0, 170.0, 358.0, 438.0, 627.0, 722.0, 836.0...</td>\n",
       "      <td>[170.0, 357.0, 438.0, 626.0, 722.0, 836.0, 101...</td>\n",
       "      <td>[0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1...</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>[Lead, Position, Claim, Evidence, Claim, Evide...</td>\n",
       "      <td>[0.0, 456.0, 638.0, 738.0, 1399.0, 1488.0, 231...</td>\n",
       "      <td>[455.0, 592.0, 738.0, 1398.0, 1487.0, 2219.0, ...</td>\n",
       "      <td>[0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1...</td>\n",
       "      <td>Driverless cars are exaclty what you would exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>[Position, Counterclaim, Rebuttal, Evidence, C...</td>\n",
       "      <td>[17.0, 64.0, 158.0, 310.0, 438.0, 551.0, 776.0...</td>\n",
       "      <td>[56.0, 157.0, 309.0, 422.0, 551.0, 775.0, 961....</td>\n",
       "      <td>[2 3 4 5 6 7 8, 10 11 12 13 14 15 16 17 18 19 ...</td>\n",
       "      <td>Dear: Principal\\n\\nI am arguing against the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001552828BD0</td>\n",
       "      <td>[Lead, Evidence, Claim, Claim, Evidence, Claim...</td>\n",
       "      <td>[0.0, 161.0, 872.0, 958.0, 1191.0, 1542.0, 161...</td>\n",
       "      <td>[160.0, 872.0, 957.0, 1190.0, 1541.0, 1612.0, ...</td>\n",
       "      <td>[0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1...</td>\n",
       "      <td>Would you be able to give your car up? Having ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>[Position, Claim, Claim, Claim, Claim, Evidenc...</td>\n",
       "      <td>[0.0, 58.0, 94.0, 206.0, 236.0, 272.0, 542.0, ...</td>\n",
       "      <td>[57.0, 91.0, 150.0, 235.0, 271.0, 542.0, 650.0...</td>\n",
       "      <td>[0 1 2 3 4 5 6 7 8 9, 10 11 12 13 14 15, 16 17...</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          classlist  \\\n",
       "0  0000D23A521A  [Position, Evidence, Evidence, Claim, Counterc...   \n",
       "1  00066EA9880D  [Lead, Position, Claim, Evidence, Claim, Evide...   \n",
       "2  000E6DE9E817  [Position, Counterclaim, Rebuttal, Evidence, C...   \n",
       "3  001552828BD0  [Lead, Evidence, Claim, Claim, Evidence, Claim...   \n",
       "4  0016926B079C  [Position, Claim, Claim, Claim, Claim, Evidenc...   \n",
       "\n",
       "                                              starts  \\\n",
       "0  [0.0, 170.0, 358.0, 438.0, 627.0, 722.0, 836.0...   \n",
       "1  [0.0, 456.0, 638.0, 738.0, 1399.0, 1488.0, 231...   \n",
       "2  [17.0, 64.0, 158.0, 310.0, 438.0, 551.0, 776.0...   \n",
       "3  [0.0, 161.0, 872.0, 958.0, 1191.0, 1542.0, 161...   \n",
       "4  [0.0, 58.0, 94.0, 206.0, 236.0, 272.0, 542.0, ...   \n",
       "\n",
       "                                                ends  \\\n",
       "0  [170.0, 357.0, 438.0, 626.0, 722.0, 836.0, 101...   \n",
       "1  [455.0, 592.0, 738.0, 1398.0, 1487.0, 2219.0, ...   \n",
       "2  [56.0, 157.0, 309.0, 422.0, 551.0, 775.0, 961....   \n",
       "3  [160.0, 872.0, 957.0, 1190.0, 1541.0, 1612.0, ...   \n",
       "4  [57.0, 91.0, 150.0, 235.0, 271.0, 542.0, 650.0...   \n",
       "\n",
       "                                   predictionstrings  \\\n",
       "0  [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1...   \n",
       "1  [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1...   \n",
       "2  [2 3 4 5 6 7 8, 10 11 12 13 14 15 16 17 18 19 ...   \n",
       "3  [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1...   \n",
       "4  [0 1 2 3 4 5 6 7 8 9, 10 11 12 13 14 15, 16 17...   \n",
       "\n",
       "                                                text  \n",
       "0  Some people belive that the so called \"face\" o...  \n",
       "1  Driverless cars are exaclty what you would exp...  \n",
       "2  Dear: Principal\\n\\nI am arguing against the po...  \n",
       "3  Would you be able to give your car up? Having ...  \n",
       "4  I think that students would benefit from learn...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing the merged data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:44:45.371472Z",
     "iopub.status.busy": "2022-05-05T20:44:45.370918Z",
     "iopub.status.idle": "2022-05-05T20:44:45.384821Z",
     "shell.execute_reply": "2022-05-05T20:44:45.383411Z",
     "shell.execute_reply.started": "2022-05-05T20:44:45.371429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15594, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of the dataset before removing outliers\n",
    "df2=df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:44:45.387282Z",
     "iopub.status.busy": "2022-05-05T20:44:45.386701Z",
     "iopub.status.idle": "2022-05-05T20:44:45.729162Z",
     "shell.execute_reply": "2022-05-05T20:44:45.728171Z",
     "shell.execute_reply.started": "2022-05-05T20:44:45.387235Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing outliers i.e. essays with more than 5 occurances of the same class are considered as outliers\n",
    "\n",
    "from collections import Counter\n",
    "res = []\n",
    "for i in range(len(df['classlist'])):\n",
    "    temp = df['classlist'][i]\n",
    "    res.append(dict(Counter(temp)))\n",
    "\n",
    "def countOcuurances(res, df2):\n",
    "    df = pd.DataFrame(res)\n",
    "    classes = ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement', 'Counterclaim', 'Rebuttal']\n",
    "    for c in classes:\n",
    "        index = df[df[c]>5].index\n",
    "        df = df.drop(index)\n",
    "        df2 = df2.drop(index)\n",
    "        \n",
    "    return df2\n",
    "\n",
    "df2 = countOcuurances(res,df2)\n",
    "df = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:44:45.731824Z",
     "iopub.status.busy": "2022-05-05T20:44:45.730674Z",
     "iopub.status.idle": "2022-05-05T20:44:45.738733Z",
     "shell.execute_reply": "2022-05-05T20:44:45.737698Z",
     "shell.execute_reply.started": "2022-05-05T20:44:45.731778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12736, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size of the dataset after removing outliers\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:44:45.741482Z",
     "iopub.status.busy": "2022-05-05T20:44:45.740464Z",
     "iopub.status.idle": "2022-05-05T20:44:45.751265Z",
     "shell.execute_reply": "2022-05-05T20:44:45.750339Z",
     "shell.execute_reply.started": "2022-05-05T20:44:45.741387Z"
    }
   },
   "outputs": [],
   "source": [
    "# debugging\n",
    "if SAMPLE: df = df.sample(n=10).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:44:45.753417Z",
     "iopub.status.busy": "2022-05-05T20:44:45.752801Z",
     "iopub.status.idle": "2022-05-05T20:44:46.343974Z",
     "shell.execute_reply": "2022-05-05T20:44:46.342985Z",
     "shell.execute_reply.started": "2022-05-05T20:44:45.753373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'classlist', 'starts', 'ends', 'predictionstrings', 'text', '__index_level_0__'],\n",
       "        num_rows: 11462\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'classlist', 'starts', 'ends', 'predictionstrings', 'text', '__index_level_0__'],\n",
       "        num_rows: 1274\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Train Test split\n",
    "from datasets import Dataset, load_metric\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "datasets = ds.train_test_split(test_size=0.1, shuffle=True, seed=42)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:44:46.347836Z",
     "iopub.status.busy": "2022-05-05T20:44:46.346295Z",
     "iopub.status.idle": "2022-05-05T20:44:55.665702Z",
     "shell.execute_reply": "2022-05-05T20:44:55.664665Z",
     "shell.execute_reply.started": "2022-05-05T20:44:46.347785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87f38169e15402f92db39294873b20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebea654320a8452ba1ba781364e20f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595b85d7579347c0a26664cbcecffa09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0979c796d760407d83d41ab087d2b41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initialing the tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:44:55.667499Z",
     "iopub.status.busy": "2022-05-05T20:44:55.667199Z",
     "iopub.status.idle": "2022-05-05T20:44:55.674447Z",
     "shell.execute_reply": "2022-05-05T20:44:55.673431Z",
     "shell.execute_reply.started": "2022-05-05T20:44:55.667457Z"
    }
   },
   "outputs": [],
   "source": [
    "# If a span is created wihout a starting token for a class\n",
    "# then we convert the first token to be the starting token\n",
    "def fix_beginnings(labels):\n",
    "    for i in range(1,len(labels)):\n",
    "        curr_lab = labels[i]\n",
    "        prev_lab = labels[i-1]\n",
    "        if curr_lab in range(7,14):\n",
    "            if prev_lab != curr_lab and prev_lab != curr_lab - 7:\n",
    "                labels[i] = curr_lab -7\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:44:55.676996Z",
     "iopub.status.busy": "2022-05-05T20:44:55.676235Z",
     "iopub.status.idle": "2022-05-05T20:44:55.691472Z",
     "shell.execute_reply": "2022-05-05T20:44:55.690442Z",
     "shell.execute_reply.started": "2022-05-05T20:44:55.676933Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizing and adding labels\n",
    "def tokenize_and_align_labels(examples):\n",
    "\n",
    "    o = tokenizer(examples['text'], truncation=True, padding=True, \n",
    "                  return_offsets_mapping=True, max_length=max_length, \n",
    "                  stride=stride, return_overflowing_tokens=True)\n",
    "    #print(o.keys())\n",
    "    sample_mapping = o[\"overflow_to_sample_mapping\"]\n",
    "    offset_mapping = o[\"offset_mapping\"]\n",
    "    \n",
    "    o[\"labels\"] = []\n",
    "\n",
    "    for i in range(len(offset_mapping)):\n",
    "                   \n",
    "        sample_index = sample_mapping[i]\n",
    "\n",
    "        labels = [l2i['O'] for i in range(len(o['input_ids'][i]))]\n",
    "\n",
    "        for label_start, label_end, label in \\\n",
    "        list(zip(examples['starts'][sample_index], examples['ends'][sample_index], examples['classlist'][sample_index])):\n",
    "            for j in range(len(labels)):\n",
    "                token_start = offset_mapping[i][j][0]\n",
    "                token_end = offset_mapping[i][j][1]\n",
    "                if token_start == label_start: \n",
    "                    labels[j] = l2i[f'B-{label}']    \n",
    "                if token_start > label_start and token_end <= label_end: \n",
    "                    labels[j] = l2i[f'I-{label}']\n",
    "\n",
    "        for k, input_id in enumerate(o['input_ids'][i]):\n",
    "            if input_id in [0,1,2]:\n",
    "                labels[k] = -100\n",
    "\n",
    "        labels = fix_beginnings(labels)         \n",
    "        o[\"labels\"].append(labels)\n",
    "        \n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:44:55.694343Z",
     "iopub.status.busy": "2022-05-05T20:44:55.693616Z",
     "iopub.status.idle": "2022-05-05T20:48:26.649932Z",
     "shell.execute_reply": "2022-05-05T20:48:26.648963Z",
     "shell.execute_reply.started": "2022-05-05T20:44:55.694299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3059e9f8ee947999a111345b621fc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e15c53742c4d3ab36a4710a06fb86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenising both train and test\n",
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True, \\\n",
    "                                  batch_size=20000, \n",
    "                                  remove_columns=datasets[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:48:26.652030Z",
     "iopub.status.busy": "2022-05-05T20:48:26.651719Z",
     "iopub.status.idle": "2022-05-05T20:48:26.659250Z",
     "shell.execute_reply": "2022-05-05T20:48:26.657887Z",
     "shell.execute_reply.started": "2022-05-05T20:48:26.651985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'offset_mapping', 'overflow_to_sample_mapping'],\n",
       "        num_rows: 11778\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'offset_mapping', 'overflow_to_sample_mapping'],\n",
       "        num_rows: 1313\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:48:26.661705Z",
     "iopub.status.busy": "2022-05-05T20:48:26.661073Z",
     "iopub.status.idle": "2022-05-05T20:48:50.838029Z",
     "shell.execute_reply": "2022-05-05T20:48:50.836998Z",
     "shell.execute_reply.started": "2022-05-05T20:48:26.661660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493d10602c134556a8b24f9686b64b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForTokenClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForTokenClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=N_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:48:50.839884Z",
     "iopub.status.busy": "2022-05-05T20:48:50.839467Z",
     "iopub.status.idle": "2022-05-05T20:48:50.846894Z",
     "shell.execute_reply": "2022-05-05T20:48:50.845752Z",
     "shell.execute_reply.started": "2022-05-05T20:48:50.839840Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:48:50.849440Z",
     "iopub.status.busy": "2022-05-05T20:48:50.848851Z",
     "iopub.status.idle": "2022-05-05T20:48:50.862931Z",
     "shell.execute_reply": "2022-05-05T20:48:50.861840Z",
     "shell.execute_reply.started": "2022-05-05T20:48:50.849360Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=BS,\n",
    "    per_device_eval_batch_size=BS,\n",
    "    num_train_epochs=N_EPOCHS,\n",
    "    weight_decay=WD,\n",
    "    report_to='wandb', \n",
    "    gradient_accumulation_steps=GRAD_ACC,\n",
    "    warmup_ratio=WARMUP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:48:50.865850Z",
     "iopub.status.busy": "2022-05-05T20:48:50.865336Z",
     "iopub.status.idle": "2022-05-05T20:48:50.871347Z",
     "shell.execute_reply": "2022-05-05T20:48:50.870027Z",
     "shell.execute_reply.started": "2022-05-05T20:48:50.865799Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:48:50.873606Z",
     "iopub.status.busy": "2022-05-05T20:48:50.873083Z",
     "iopub.status.idle": "2022-05-05T20:48:51.876521Z",
     "shell.execute_reply": "2022-05-05T20:48:51.875481Z",
     "shell.execute_reply.started": "2022-05-05T20:48:50.873564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b3ab3fc6d7434ab46d406eabc9e3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading Metric\n",
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:48:51.878593Z",
     "iopub.status.busy": "2022-05-05T20:48:51.878177Z",
     "iopub.status.idle": "2022-05-05T20:48:51.890764Z",
     "shell.execute_reply": "2022-05-05T20:48:51.889639Z",
     "shell.execute_reply.started": "2022-05-05T20:48:51.878549Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove special tokens\n",
    "    true_predictions = [\n",
    "        [i2l[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [i2l[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:48:51.892748Z",
     "iopub.status.busy": "2022-05-05T20:48:51.892335Z",
     "iopub.status.idle": "2022-05-05T20:49:00.392092Z",
     "shell.execute_reply": "2022-05-05T20:49:00.391089Z",
     "shell.execute_reply.started": "2022-05-05T20:48:51.892685Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:49:00.397930Z",
     "iopub.status.busy": "2022-05-05T20:49:00.397689Z",
     "iopub.status.idle": "2022-05-05T20:49:00.402871Z",
     "shell.execute_reply": "2022-05-05T20:49:00.402023Z",
     "shell.execute_reply.started": "2022-05-05T20:49:00.397901Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T20:49:00.404665Z",
     "iopub.status.busy": "2022-05-05T20:49:00.404112Z",
     "iopub.status.idle": "2022-05-06T00:48:33.962334Z",
     "shell.execute_reply": "2022-05-06T00:48:33.961157Z",
     "shell.execute_reply.started": "2022-05-05T20:49:00.404628Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: offset_mapping, overflow_to_sample_mapping.\n",
      "***** Running training *****\n",
      "  Num examples = 11778\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 1840\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1840' max='1840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1840/1840 3:59:11, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.028900</td>\n",
       "      <td>0.654350</td>\n",
       "      <td>0.102136</td>\n",
       "      <td>0.217217</td>\n",
       "      <td>0.138941</td>\n",
       "      <td>0.787744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.621500</td>\n",
       "      <td>0.605735</td>\n",
       "      <td>0.143180</td>\n",
       "      <td>0.284232</td>\n",
       "      <td>0.190431</td>\n",
       "      <td>0.797515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.525700</td>\n",
       "      <td>0.593650</td>\n",
       "      <td>0.159190</td>\n",
       "      <td>0.299187</td>\n",
       "      <td>0.207810</td>\n",
       "      <td>0.805811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.449300</td>\n",
       "      <td>0.618323</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>0.313020</td>\n",
       "      <td>0.223393</td>\n",
       "      <td>0.802356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>0.641289</td>\n",
       "      <td>0.171629</td>\n",
       "      <td>0.322740</td>\n",
       "      <td>0.224090</td>\n",
       "      <td>0.799704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: offset_mapping, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1313\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to longformer-base-4096-finetuned-ner/checkpoint-368\n",
      "Configuration saved in longformer-base-4096-finetuned-ner/checkpoint-368/config.json\n",
      "Model weights saved in longformer-base-4096-finetuned-ner/checkpoint-368/pytorch_model.bin\n",
      "tokenizer config file saved in longformer-base-4096-finetuned-ner/checkpoint-368/tokenizer_config.json\n",
      "Special tokens file saved in longformer-base-4096-finetuned-ner/checkpoint-368/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: offset_mapping, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1313\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to longformer-base-4096-finetuned-ner/checkpoint-736\n",
      "Configuration saved in longformer-base-4096-finetuned-ner/checkpoint-736/config.json\n",
      "Model weights saved in longformer-base-4096-finetuned-ner/checkpoint-736/pytorch_model.bin\n",
      "tokenizer config file saved in longformer-base-4096-finetuned-ner/checkpoint-736/tokenizer_config.json\n",
      "Special tokens file saved in longformer-base-4096-finetuned-ner/checkpoint-736/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: offset_mapping, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1313\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to longformer-base-4096-finetuned-ner/checkpoint-1104\n",
      "Configuration saved in longformer-base-4096-finetuned-ner/checkpoint-1104/config.json\n",
      "Model weights saved in longformer-base-4096-finetuned-ner/checkpoint-1104/pytorch_model.bin\n",
      "tokenizer config file saved in longformer-base-4096-finetuned-ner/checkpoint-1104/tokenizer_config.json\n",
      "Special tokens file saved in longformer-base-4096-finetuned-ner/checkpoint-1104/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: offset_mapping, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1313\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to longformer-base-4096-finetuned-ner/checkpoint-1472\n",
      "Configuration saved in longformer-base-4096-finetuned-ner/checkpoint-1472/config.json\n",
      "Model weights saved in longformer-base-4096-finetuned-ner/checkpoint-1472/pytorch_model.bin\n",
      "tokenizer config file saved in longformer-base-4096-finetuned-ner/checkpoint-1472/tokenizer_config.json\n",
      "Special tokens file saved in longformer-base-4096-finetuned-ner/checkpoint-1472/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: offset_mapping, overflow_to_sample_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1313\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to longformer-base-4096-finetuned-ner/checkpoint-1840\n",
      "Configuration saved in longformer-base-4096-finetuned-ner/checkpoint-1840/config.json\n",
      "Model weights saved in longformer-base-4096-finetuned-ner/checkpoint-1840/pytorch_model.bin\n",
      "tokenizer config file saved in longformer-base-4096-finetuned-ner/checkpoint-1840/tokenizer_config.json\n",
      "Special tokens file saved in longformer-base-4096-finetuned-ner/checkpoint-1840/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅█▇▆</td></tr><tr><td>eval/f1</td><td>▁▅▇██</td></tr><tr><td>eval/loss</td><td>█▂▁▄▆</td></tr><tr><td>eval/precision</td><td>▁▅▇██</td></tr><tr><td>eval/recall</td><td>▁▅▆▇█</td></tr><tr><td>eval/runtime</td><td>▆▄█▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▃▅▁▂█</td></tr><tr><td>eval/steps_per_second</td><td>▃▅▁▂█</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.7997</td></tr><tr><td>eval/f1</td><td>0.22409</td></tr><tr><td>eval/loss</td><td>0.64129</td></tr><tr><td>eval/precision</td><td>0.17163</td></tr><tr><td>eval/recall</td><td>0.32274</td></tr><tr><td>eval/runtime</td><td>109.5241</td></tr><tr><td>eval/samples_per_second</td><td>11.988</td></tr><tr><td>eval/steps_per_second</td><td>3.004</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>1840</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3923</td></tr><tr><td>train/total_flos</td><td>3.847061386528358e+16</td></tr><tr><td>train/train_loss</td><td>0.60354</td></tr><tr><td>train/train_runtime</td><td>14366.7392</td></tr><tr><td>train/train_samples_per_second</td><td>4.099</td></tr><tr><td>train/train_steps_per_second</td><td>0.128</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /kaggle/working/wandb/offline-run-20220505_204903-2kdchg1t<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20220505_204903-2kdchg1t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T00:48:33.970656Z",
     "iopub.status.busy": "2022-05-06T00:48:33.968674Z",
     "iopub.status.idle": "2022-05-06T00:48:35.254502Z",
     "shell.execute_reply": "2022-05-06T00:48:35.253280Z",
     "shell.execute_reply.started": "2022-05-06T00:48:33.970443Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to longformer-base-4096-4\n",
      "Configuration saved in longformer-base-4096-4/config.json\n",
      "Model weights saved in longformer-base-4096-4/pytorch_model.bin\n",
      "tokenizer config file saved in longformer-base-4096-4/tokenizer_config.json\n",
      "Special tokens file saved in longformer-base-4096-4/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T00:48:35.256621Z",
     "iopub.status.busy": "2022-05-06T00:48:35.256332Z",
     "iopub.status.idle": "2022-05-06T00:48:35.270048Z",
     "shell.execute_reply": "2022-05-06T00:48:35.268938Z",
     "shell.execute_reply.started": "2022-05-06T00:48:35.256580Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_for_test(examples):\n",
    "\n",
    "    o = tokenizer(examples['text'], truncation=True, return_offsets_mapping=True, max_length=4096)\n",
    "\n",
    "    offset_mapping = o[\"offset_mapping\"]\n",
    "    \n",
    "    o[\"labels\"] = []\n",
    "\n",
    "    for i in range(len(offset_mapping)):\n",
    "                   \n",
    "        labels = [l2i['O'] for i in range(len(o['input_ids'][i]))]\n",
    "\n",
    "        for label_start, label_end, label in \\\n",
    "        list(zip(examples['starts'][i], examples['ends'][i], examples['classlist'][i])):\n",
    "            for j in range(len(labels)):\n",
    "                token_start = offset_mapping[i][j][0]\n",
    "                token_end = offset_mapping[i][j][1]\n",
    "                if token_start == label_start: \n",
    "                    labels[j] = l2i[f'B-{label}']    \n",
    "                if token_start > label_start and token_end <= label_end: \n",
    "                    labels[j] = l2i[f'I-{label}']\n",
    "\n",
    "        for k, input_id in enumerate(o['input_ids'][i]):\n",
    "            if input_id in [0,1,2]:\n",
    "                labels[k] = -100\n",
    "\n",
    "        labels = fix_beginnings(labels)\n",
    "                   \n",
    "        o[\"labels\"].append(labels)\n",
    "        \n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T00:48:35.272204Z",
     "iopub.status.busy": "2022-05-06T00:48:35.271824Z",
     "iopub.status.idle": "2022-05-06T00:50:18.662697Z",
     "shell.execute_reply": "2022-05-06T00:50:18.661476Z",
     "shell.execute_reply.started": "2022-05-06T00:48:35.272160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c7bb3def5542b8ba2a69394d9c629c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2691b1a4b5c248abb5dfd8a6964e7ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['__index_level_0__', 'attention_mask', 'classlist', 'ends', 'id', 'input_ids', 'labels', 'offset_mapping', 'predictionstrings', 'starts', 'text'],\n",
       "        num_rows: 11462\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['__index_level_0__', 'attention_mask', 'classlist', 'ends', 'id', 'input_ids', 'labels', 'offset_mapping', 'predictionstrings', 'starts', 'text'],\n",
       "        num_rows: 1274\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test = datasets.map(tokenize_for_test, batched=True)\n",
    "tokenized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T00:50:18.665677Z",
     "iopub.status.busy": "2022-05-06T00:50:18.664554Z",
     "iopub.status.idle": "2022-05-06T00:50:22.540835Z",
     "shell.execute_reply": "2022-05-06T00:50:22.539789Z",
     "shell.execute_reply.started": "2022-05-06T00:50:18.665613Z"
    }
   },
   "outputs": [],
   "source": [
    "# ground truth for test data\n",
    "\n",
    "l = []\n",
    "for example in tokenized_test['test']:\n",
    "    for c, p in list(zip(example['classlist'], example['predictionstrings'])):\n",
    "        l.append({\n",
    "            'id': example['id'],\n",
    "            'discourse_type': c,\n",
    "            'predictionstring': p,\n",
    "        })\n",
    "    \n",
    "gt_df = pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T00:50:22.542927Z",
     "iopub.status.busy": "2022-05-06T00:50:22.542596Z",
     "iopub.status.idle": "2022-05-06T00:50:22.553882Z",
     "shell.execute_reply": "2022-05-06T00:50:22.552496Z",
     "shell.execute_reply.started": "2022-05-06T00:50:22.542885Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('../input/feedback-prize-2021/train')\n",
    "\n",
    "colors = {\n",
    "            'Lead': '#8000ff',\n",
    "            'Position': '#2b7ff6',\n",
    "            'Evidence': '#2adddd',\n",
    "            'Claim': '#80ffb4',\n",
    "            'Concluding Statement': 'd4dd80',\n",
    "            'Counterclaim': '#ff8042',\n",
    "            'Rebuttal': '#ff0000',\n",
    "            'Other': '#007f00',\n",
    "         }\n",
    "\n",
    "def visualize(df, text):\n",
    "    ents = []\n",
    "    example = df['id'].loc[0]\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        ents.append({\n",
    "                        'start': int(row['discourse_start']), \n",
    "                         'end': int(row['discourse_end']), \n",
    "                         'label': row['discourse_type']\n",
    "                    })\n",
    "\n",
    "    doc2 = {\n",
    "        \"text\": text,\n",
    "        \"ents\": ents,\n",
    "        \"title\": example\n",
    "    }\n",
    "\n",
    "    options = {\"ents\": train.discourse_type.unique().tolist() + ['Other'], \"colors\": colors}\n",
    "    displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T00:50:22.556365Z",
     "iopub.status.busy": "2022-05-06T00:50:22.556024Z",
     "iopub.status.idle": "2022-05-06T00:52:15.414376Z",
     "shell.execute_reply": "2022-05-06T00:52:15.413172Z",
     "shell.execute_reply.started": "2022-05-06T00:50:22.556321Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: id, ends, starts, offset_mapping, __index_level_0__, classlist, predictionstrings, text.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1274\n",
      "  Batch size = 4\n",
      "Input ids are automatically padded from 462 to 512 to be a multiple of `config.attention_window`: 512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='319' max='319' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [319/319 01:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 513 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 944 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1649 to 2048 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 749 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 637 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 935 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 694 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 824 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 469 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 825 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 649 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 786 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 535 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 596 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 586 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 709 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 836 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 575 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 777 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 742 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 935 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 921 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 976 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 623 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 968 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 520 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 632 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 527 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 549 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 629 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1159 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 486 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 526 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 643 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 655 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 535 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1130 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 941 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 546 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 683 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 878 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 677 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 531 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 595 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 834 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 469 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 350 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 638 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 650 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 369 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 781 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 552 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 710 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1104 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 446 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 753 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 805 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 596 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 870 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 690 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 755 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 687 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 434 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 509 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 858 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 518 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 593 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 720 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 430 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 369 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 772 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 820 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 449 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 586 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 697 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 545 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 924 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 654 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 710 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 561 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 897 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1125 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 408 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 641 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 592 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1135 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 662 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 803 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 618 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 772 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 788 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 728 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 758 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 574 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 812 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 788 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 507 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 841 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 549 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 948 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 624 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 582 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1272 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 715 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 500 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 624 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 695 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 656 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 342 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1179 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 595 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 582 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 547 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 992 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 943 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 768 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 768 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 680 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 740 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 621 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 464 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 602 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 563 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 553 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 661 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 555 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 671 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 528 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 589 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 739 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 622 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 651 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 661 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 589 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 810 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 391 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 650 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 574 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 599 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 798 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 988 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 860 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 486 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 469 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 573 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 721 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 918 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 481 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 813 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 423 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 919 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 3991 to 4096 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 775 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 973 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 774 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 692 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1027 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 432 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 745 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 591 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 663 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 777 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 729 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 610 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 419 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 786 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 563 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 807 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 666 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 519 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 859 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 545 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 908 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 570 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 622 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 714 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 733 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1074 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 591 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1242 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 746 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 425 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 703 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 807 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 606 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 854 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 741 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 869 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 437 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 453 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 689 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 653 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 782 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 340 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 516 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1154 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 758 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 597 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 759 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 884 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 566 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 626 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 448 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 745 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 597 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 528 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 814 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 507 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 848 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 749 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1090 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 352 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 859 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 563 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 797 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 390 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 590 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 719 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1027 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 2349 to 2560 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 853 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 654 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 647 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 600 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 501 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 722 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 683 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 629 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 827 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 966 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 485 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 656 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 497 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 565 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1236 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 599 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 784 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 525 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 417 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 895 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 863 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 549 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 727 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 480 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 670 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 618 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 838 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 707 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 568 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 979 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 647 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1068 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 495 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 569 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 422 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 605 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 612 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1044 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1131 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 452 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 577 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 750 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 438 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 840 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 473 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 967 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 386 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 504 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 681 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 787 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 469 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1193 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 755 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 666 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 654 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 670 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 594 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 822 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 711 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 667 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 814 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 484 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 670 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 544 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 475 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 640 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1639 to 2048 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 599 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 863 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 942 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 466 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 519 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1165 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 383 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 898 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 582 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 770 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 659 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 522 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 355 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1022 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 548 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 633 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 698 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 491 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1059 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 565 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 901 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 870 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 647 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 444 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 495 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 536 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 381 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 509 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 467 to 512 to be a multiple of `config.attention_window`: 512\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_test['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T00:52:15.416902Z",
     "iopub.status.busy": "2022-05-06T00:52:15.416599Z",
     "iopub.status.idle": "2022-05-06T00:52:15.511772Z",
     "shell.execute_reply": "2022-05-06T00:52:15.510733Z",
     "shell.execute_reply.started": "2022-05-06T00:52:15.416860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1274, 4096)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.argmax(predictions, axis=-1)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T00:52:15.514045Z",
     "iopub.status.busy": "2022-05-06T00:52:15.513695Z",
     "iopub.status.idle": "2022-05-06T00:52:15.531761Z",
     "shell.execute_reply": "2022-05-06T00:52:15.530404Z",
     "shell.execute_reply.started": "2022-05-06T00:52:15.514001Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_class(c):\n",
    "    if c == 14: return 'Other'\n",
    "    else: return i2l[c][2:]\n",
    "\n",
    "def pred2span(pred, example, viz=False, test=False):\n",
    "    example_id = example['id']\n",
    "    n_tokens = len(example['input_ids'])\n",
    "    classes = []\n",
    "    all_span = []\n",
    "    for i, c in enumerate(pred.tolist()):\n",
    "        if i == n_tokens-1:\n",
    "            break\n",
    "        if i == 0:\n",
    "            cur_span = example['offset_mapping'][i]\n",
    "            classes.append(get_class(c))\n",
    "        elif i > 0 and (c == pred[i-1] or (c-7) == pred[i-1]):\n",
    "            cur_span[1] = example['offset_mapping'][i][1]\n",
    "        else:\n",
    "            all_span.append(cur_span)\n",
    "            cur_span = example['offset_mapping'][i]\n",
    "            classes.append(get_class(c))\n",
    "    all_span.append(cur_span)\n",
    "    \n",
    "    if test: text = get_test_text(example_id)\n",
    "    else: text = get_raw_text(example_id)\n",
    "    \n",
    "    # abra ka dabra se soli fanta ko pelo\n",
    "    \n",
    "    # map token ids to word (whitespace) token ids\n",
    "    predstrings = []\n",
    "    for span in all_span:\n",
    "        span_start = span[0]\n",
    "        span_end = span[1]\n",
    "        before = text[:span_start]\n",
    "        token_start = len(before.split())\n",
    "        if len(before) == 0: token_start = 0\n",
    "        elif before[-1] != ' ': token_start -= 1\n",
    "        num_tkns = len(text[span_start:span_end+1].split())\n",
    "        tkns = [str(x) for x in range(token_start, token_start+num_tkns)]\n",
    "        predstring = ' '.join(tkns)\n",
    "        predstrings.append(predstring)\n",
    "                    \n",
    "    rows = []\n",
    "    for c, span, predstring in zip(classes, all_span, predstrings):\n",
    "        e = {\n",
    "            'id': example_id,\n",
    "            'discourse_type': c,\n",
    "            'predictionstring': predstring,\n",
    "            'discourse_start': span[0],\n",
    "            'discourse_end': span[1],\n",
    "            'discourse': text[span[0]:span[1]+1]\n",
    "        }\n",
    "        rows.append(e)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['length'] = df['discourse'].apply(lambda t: len(t.split()))\n",
    "    \n",
    "    # short spans are likely to be false positives, we can choose a min number of tokens based on validation\n",
    "    df = df[df.length > min_tokens].reset_index(drop=True)\n",
    "    if viz: visualize(df, text)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T00:52:15.534059Z",
     "iopub.status.busy": "2022-05-06T00:52:15.533665Z",
     "iopub.status.idle": "2022-05-06T00:52:32.132965Z",
     "shell.execute_reply": "2022-05-06T00:52:32.130999Z",
     "shell.execute_reply.started": "2022-05-06T00:52:15.534016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse</th>\n",
       "      <th>length</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>1</td>\n",
       "      <td>368</td>\n",
       "      <td>chools are offering distant learning for stude...</td>\n",
       "      <td>62</td>\n",
       "      <td>Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Position</td>\n",
       "      <td>62 63 64 65 66 67 68 69 70 71 72 73 74 75 76</td>\n",
       "      <td>369</td>\n",
       "      <td>457</td>\n",
       "      <td>Online classes would help tons of students mov...</td>\n",
       "      <td>15</td>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Claim</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "      <td>460</td>\n",
       "      <td>613</td>\n",
       "      <td>Most of the people failing classes or didn't g...</td>\n",
       "      <td>27</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>104 105 106 107 108 109 110 111 112 113 114 11...</td>\n",
       "      <td>614</td>\n",
       "      <td>1367</td>\n",
       "      <td>A big example of this is working. They have to...</td>\n",
       "      <td>134</td>\n",
       "      <td>Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Claim</td>\n",
       "      <td>237 238 239 240 241 242 243 244 245 246 247 24...</td>\n",
       "      <td>1368</td>\n",
       "      <td>1460</td>\n",
       "      <td>Another case where distant learning may come i...</td>\n",
       "      <td>16</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58F8F0F77817</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 3...</td>\n",
       "      <td>100</td>\n",
       "      <td>463</td>\n",
       "      <td>\"Its a ood opportunity to take away stress and...</td>\n",
       "      <td>70</td>\n",
       "      <td>Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58F8F0F77817</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>94 95 96 97 98 99 100 101 102 103 104 105 106 ...</td>\n",
       "      <td>501</td>\n",
       "      <td>1021</td>\n",
       "      <td>you can use someonjes elses gas instead of you...</td>\n",
       "      <td>101</td>\n",
       "      <td>Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58F8F0F77817</td>\n",
       "      <td>Other</td>\n",
       "      <td>195 196 197 198 199 200 201 202 203 204</td>\n",
       "      <td>1026</td>\n",
       "      <td>1089</td>\n",
       "      <td>iting car usage also relieves stress for some ...</td>\n",
       "      <td>10</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58F8F0F77817</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>205 206 207 208 209 210 211 212 213 214 215 21...</td>\n",
       "      <td>1090</td>\n",
       "      <td>1464</td>\n",
       "      <td>Some people that i know get really flustered e...</td>\n",
       "      <td>69</td>\n",
       "      <td>Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58F8F0F77817</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>276 277 278 279 280 281 282 283 284 285 286 28...</td>\n",
       "      <td>1479</td>\n",
       "      <td>1561</td>\n",
       "      <td>limited car usage is good because it save sgas...</td>\n",
       "      <td>15</td>\n",
       "      <td>Concluding Statement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12284 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id        discourse_type  \\\n",
       "0   F4FD84517F40                  Lead   \n",
       "1   F4FD84517F40              Position   \n",
       "2   F4FD84517F40                 Claim   \n",
       "3   F4FD84517F40              Evidence   \n",
       "4   F4FD84517F40                 Claim   \n",
       "..           ...                   ...   \n",
       "1   58F8F0F77817              Evidence   \n",
       "2   58F8F0F77817              Evidence   \n",
       "3   58F8F0F77817                 Other   \n",
       "4   58F8F0F77817              Evidence   \n",
       "5   58F8F0F77817  Concluding Statement   \n",
       "\n",
       "                                     predictionstring  discourse_start  \\\n",
       "0   0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...                1   \n",
       "1        62 63 64 65 66 67 68 69 70 71 72 73 74 75 76              369   \n",
       "2   76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...              460   \n",
       "3   104 105 106 107 108 109 110 111 112 113 114 11...              614   \n",
       "4   237 238 239 240 241 242 243 244 245 246 247 24...             1368   \n",
       "..                                                ...              ...   \n",
       "1   18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 3...              100   \n",
       "2   94 95 96 97 98 99 100 101 102 103 104 105 106 ...              501   \n",
       "3             195 196 197 198 199 200 201 202 203 204             1026   \n",
       "4   205 206 207 208 209 210 211 212 213 214 215 21...             1090   \n",
       "5   276 277 278 279 280 281 282 283 284 285 286 28...             1479   \n",
       "\n",
       "    discourse_end                                          discourse  length  \\\n",
       "0             368  chools are offering distant learning for stude...      62   \n",
       "1             457  Online classes would help tons of students mov...      15   \n",
       "2             613  Most of the people failing classes or didn't g...      27   \n",
       "3            1367  A big example of this is working. They have to...     134   \n",
       "4            1460  Another case where distant learning may come i...      16   \n",
       "..            ...                                                ...     ...   \n",
       "1             463  \"Its a ood opportunity to take away stress and...      70   \n",
       "2            1021  you can use someonjes elses gas instead of you...     101   \n",
       "3            1089  iting car usage also relieves stress for some ...      10   \n",
       "4            1464  Some people that i know get really flustered e...      69   \n",
       "5            1561  limited car usage is good because it save sgas...      15   \n",
       "\n",
       "                   class  \n",
       "0                   Lead  \n",
       "1               Position  \n",
       "2                  Claim  \n",
       "3               Evidence  \n",
       "4                  Claim  \n",
       "..                   ...  \n",
       "1               Evidence  \n",
       "2               Evidence  \n",
       "3                  Other  \n",
       "4               Evidence  \n",
       "5   Concluding Statement  \n",
       "\n",
       "[12284 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for i in range(len(tokenized_test['test'])):\n",
    "    dfs.append(pred2span(preds[i], tokenized_test['test'][i]))\n",
    "\n",
    "pred_df = pd.concat(dfs, axis=0)\n",
    "pred_df['class'] = pred_df['discourse_type']\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T00:52:32.135568Z",
     "iopub.status.busy": "2022-05-06T00:52:32.134677Z",
     "iopub.status.idle": "2022-05-06T00:52:32.160029Z",
     "shell.execute_reply": "2022-05-06T00:52:32.158677Z",
     "shell.execute_reply.started": "2022-05-06T00:52:32.135437Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_overlap(row):\n",
    "    #Calculates the overlap between prediction and ground truth and \n",
    "    #overlap percentages used for determining true positives.\n",
    "    set_pred = set(row.predictionstring_pred.split(\" \"))\n",
    "    set_gt = set(row.predictionstring_gt.split(\" \"))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter / len_pred\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def score_feedback_comp_micro(pred_df, gt_df):\n",
    "    gt_df = (\n",
    "        gt_df[[\"id\", \"discourse_type\", \"predictionstring\"]]\n",
    "        .reset_index(drop=True)\n",
    "        .copy()\n",
    "    )\n",
    "    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n",
    "    pred_df[\"pred_id\"] = pred_df.index\n",
    "    gt_df[\"gt_id\"] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(\n",
    "        gt_df,\n",
    "        left_on=[\"id\", \"class\"],\n",
    "        right_on=[\"id\", \"discourse_type\"],\n",
    "        how=\"outer\",\n",
    "        suffixes=(\"_pred\", \"_gt\"),\n",
    "    )\n",
    "    joined[\"predictionstring_gt\"] = joined[\"predictionstring_gt\"].fillna(\" \")\n",
    "    joined[\"predictionstring_pred\"] = joined[\"predictionstring_pred\"].fillna(\" \")\n",
    "\n",
    "    joined[\"overlaps\"] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5,\n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined[\"overlap1\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[0])\n",
    "    joined[\"overlap2\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "    joined[\"potential_TP\"] = (joined[\"overlap1\"] >= 0.5) & (joined[\"overlap2\"] >= 0.5)\n",
    "    joined[\"max_overlap\"] = joined[[\"overlap1\", \"overlap2\"]].max(axis=1)\n",
    "    tp_pred_ids = (\n",
    "        joined.query(\"potential_TP\")\n",
    "        .sort_values(\"max_overlap\", ascending=False)\n",
    "        .groupby([\"id\", \"predictionstring_gt\"])\n",
    "        .first()[\"pred_id\"]\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined[\"pred_id\"].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query(\"potential_TP\")[\"gt_id\"].unique()\n",
    "    unmatched_gt_ids = [c for c in joined[\"gt_id\"].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    # calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5 * (FP + FN))\n",
    "    return my_f1_score\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df, gt_df, return_class_scores=False):\n",
    "    class_scores = {}\n",
    "    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n",
    "    for discourse_type, gt_subset in gt_df.groupby(\"discourse_type\"):\n",
    "        pred_subset = (\n",
    "            pred_df.loc[pred_df[\"class\"] == discourse_type]\n",
    "            .reset_index(drop=True)\n",
    "            .copy()\n",
    "        )\n",
    "        class_score = score_feedback_comp_micro(pred_subset, gt_subset)\n",
    "        class_scores[discourse_type] = class_score\n",
    "    f1 = np.mean([v for v in class_scores.values()])\n",
    "    if return_class_scores:\n",
    "        return f1, class_scores\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-1 Score on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T00:52:32.162313Z",
     "iopub.status.busy": "2022-05-06T00:52:32.161593Z",
     "iopub.status.idle": "2022-05-06T00:52:34.618827Z",
     "shell.execute_reply": "2022-05-06T00:52:34.617895Z",
     "shell.execute_reply.started": "2022-05-06T00:52:32.162260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6006660382605588,\n",
       " {'Claim': 0.5415699024616814,\n",
       "  'Concluding Statement': 0.7681779298545766,\n",
       "  'Counterclaim': 0.4782608695652174,\n",
       "  'Evidence': 0.6717257621352872,\n",
       "  'Lead': 0.7335858585858586,\n",
       "  'Position': 0.6224530563324011,\n",
       "  'Rebuttal': 0.3888888888888889})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_feedback_comp(pred_df, gt_df, return_class_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo - Visualising Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T01:02:04.414512Z",
     "iopub.status.busy": "2022-05-06T01:02:04.413797Z",
     "iopub.status.idle": "2022-05-06T01:02:04.430777Z",
     "shell.execute_reply": "2022-05-06T01:02:04.429553Z",
     "shell.execute_reply.started": "2022-05-06T01:02:04.414435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse</th>\n",
       "      <th>length</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>1</td>\n",
       "      <td>368</td>\n",
       "      <td>chools are offering distant learning for stude...</td>\n",
       "      <td>62</td>\n",
       "      <td>Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Position</td>\n",
       "      <td>62 63 64 65 66 67 68 69 70 71 72 73 74 75 76</td>\n",
       "      <td>369</td>\n",
       "      <td>457</td>\n",
       "      <td>Online classes would help tons of students mov...</td>\n",
       "      <td>15</td>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Claim</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "      <td>460</td>\n",
       "      <td>613</td>\n",
       "      <td>Most of the people failing classes or didn't g...</td>\n",
       "      <td>27</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>104 105 106 107 108 109 110 111 112 113 114 11...</td>\n",
       "      <td>614</td>\n",
       "      <td>1367</td>\n",
       "      <td>A big example of this is working. They have to...</td>\n",
       "      <td>134</td>\n",
       "      <td>Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Claim</td>\n",
       "      <td>237 238 239 240 241 242 243 244 245 246 247 24...</td>\n",
       "      <td>1368</td>\n",
       "      <td>1460</td>\n",
       "      <td>Another case where distant learning may come i...</td>\n",
       "      <td>16</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id discourse_type  \\\n",
       "0  F4FD84517F40           Lead   \n",
       "1  F4FD84517F40       Position   \n",
       "2  F4FD84517F40          Claim   \n",
       "3  F4FD84517F40       Evidence   \n",
       "4  F4FD84517F40          Claim   \n",
       "\n",
       "                                    predictionstring  discourse_start  \\\n",
       "0  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...                1   \n",
       "1       62 63 64 65 66 67 68 69 70 71 72 73 74 75 76              369   \n",
       "2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...              460   \n",
       "3  104 105 106 107 108 109 110 111 112 113 114 11...              614   \n",
       "4  237 238 239 240 241 242 243 244 245 246 247 24...             1368   \n",
       "\n",
       "   discourse_end                                          discourse  length  \\\n",
       "0            368  chools are offering distant learning for stude...      62   \n",
       "1            457  Online classes would help tons of students mov...      15   \n",
       "2            613  Most of the people failing classes or didn't g...      27   \n",
       "3           1367  A big example of this is working. They have to...     134   \n",
       "4           1460  Another case where distant learning may come i...      16   \n",
       "\n",
       "      class  \n",
       "0      Lead  \n",
       "1  Position  \n",
       "2     Claim  \n",
       "3  Evidence  \n",
       "4     Claim  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T00:52:34.647555Z",
     "iopub.status.busy": "2022-05-06T00:52:34.647153Z",
     "iopub.status.idle": "2022-05-06T00:52:34.688809Z",
     "shell.execute_reply": "2022-05-06T00:52:34.687943Z",
     "shell.execute_reply.started": "2022-05-06T00:52:34.647493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><h2 style=\"margin: 0\">F4FD84517F40</h2>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">S\n",
       "<mark class=\"entity\" style=\"background: #8000ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chools are offering distant learning for students to attend classes off campus. Many students are saying this is great and they are taking the offer to continue and better their education. On the other hand, some say that this is not the best idea for schooling. Schools want to give students an opportunity to better their learning and stay connected with education.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Lead</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #2b7ff6; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Online classes would help tons of students move closer to graduation and a better future\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Position</span>\n",
       "</mark>\n",
       ".</br></br>\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Most of the people failing classes or didn't graduate the first time around have things they have to do outside of school to help support their families.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    A big example of this is working. They have to work to make money for their families but without all of the education they need, they can't work for a better paying job. Therefore, lots of people are working multiple jobs to support families; this is leaving them no time to spend six to eight hours of the day in a building. Another example is that nowadays many teens are having to stay home to watch their own child or watching a family member because of finances in their home. Although being home may help out with home situations, students grades are dropping due to the amount of absent days in classes. Online classes and video conferencing would benefit these students by allowing them to take classes at night and/or multitask during the day.\n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Another case where distant learning may come in use is for students very involved in sports.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Doing a sport can be a big responsibility. Sports are very time consuming, although some athletes make it look easy, there is a lot that goes into playing. Many levels of sports may require leaving the state or country for days, sometimes even weeks. While playing a sport it is easy to be injured or become sick. Furthermore, students are loosing class time and unable to make up for missed days in little time. Distant learning would be beneficial for those who travel so they can take their school work along and manage their free time. Online classes also help when they are sick or injured to give them time to rest and heal and still not miss out on continuing to learning.\n",
       "\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n",
       "</mark>\n",
       "</br>\n",
       "<mark class=\"entity\" style=\"background: d4dd80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    In conclusion, yes distant learning as an option to students is very beneficial. Allowing students to attend class from home or while traveling could get more and more people willing to go further in learning.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Concluding Statement</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>1</td>\n",
       "      <td>368</td>\n",
       "      <td>chools are offering distant learning for stude...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Position</td>\n",
       "      <td>62 63 64 65 66 67 68 69 70 71 72 73 74 75 76</td>\n",
       "      <td>369</td>\n",
       "      <td>457</td>\n",
       "      <td>Online classes would help tons of students mov...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Claim</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "      <td>460</td>\n",
       "      <td>613</td>\n",
       "      <td>Most of the people failing classes or didn't g...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>104 105 106 107 108 109 110 111 112 113 114 11...</td>\n",
       "      <td>614</td>\n",
       "      <td>1367</td>\n",
       "      <td>A big example of this is working. They have to...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Claim</td>\n",
       "      <td>237 238 239 240 241 242 243 244 245 246 247 24...</td>\n",
       "      <td>1368</td>\n",
       "      <td>1460</td>\n",
       "      <td>Another case where distant learning may come i...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>254 255 256 257 258 259 260 261 262 263 264 26...</td>\n",
       "      <td>1461</td>\n",
       "      <td>2141</td>\n",
       "      <td>Doing a sport can be a big responsibility. Spo...</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F4FD84517F40</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>376 377 378 379 380 381 382 383 384 385 386 38...</td>\n",
       "      <td>2142</td>\n",
       "      <td>2351</td>\n",
       "      <td>In conclusion, yes distant learning as an opti...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id        discourse_type  \\\n",
       "0  F4FD84517F40                  Lead   \n",
       "1  F4FD84517F40              Position   \n",
       "2  F4FD84517F40                 Claim   \n",
       "3  F4FD84517F40              Evidence   \n",
       "4  F4FD84517F40                 Claim   \n",
       "5  F4FD84517F40              Evidence   \n",
       "6  F4FD84517F40  Concluding Statement   \n",
       "\n",
       "                                    predictionstring  discourse_start  \\\n",
       "0  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...                1   \n",
       "1       62 63 64 65 66 67 68 69 70 71 72 73 74 75 76              369   \n",
       "2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...              460   \n",
       "3  104 105 106 107 108 109 110 111 112 113 114 11...              614   \n",
       "4  237 238 239 240 241 242 243 244 245 246 247 24...             1368   \n",
       "5  254 255 256 257 258 259 260 261 262 263 264 26...             1461   \n",
       "6  376 377 378 379 380 381 382 383 384 385 386 38...             2142   \n",
       "\n",
       "   discourse_end                                          discourse  length  \n",
       "0            368  chools are offering distant learning for stude...      62  \n",
       "1            457  Online classes would help tons of students mov...      15  \n",
       "2            613  Most of the people failing classes or didn't g...      27  \n",
       "3           1367  A big example of this is working. They have to...     134  \n",
       "4           1460  Another case where distant learning may come i...      16  \n",
       "5           2141  Doing a sport can be a big responsibility. Spo...     123  \n",
       "6           2351  In conclusion, yes distant learning as an opti...      35  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2span(preds[0], tokenized_test['test'][0], viz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
